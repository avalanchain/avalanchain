# HTTP Configurations
http.interface = "localhost"
http.port = 9911

akka {
  #version = 2.5-M1

  # Loggers to register at boot time (akka.event.Logging$DefaultLogger logs
  # to STDOUT)
  loggers = ["akka.event.slf4j.Slf4jLogger"]

  # Log level used by the configured loggers (see "loggers") as soon
  # as they have been started; before that, see "stdout-loglevel"
  # Options: OFF, ERROR, WARNING, INFO, DEBUG
  loglevel = "DEBUG"

  # Log level for the very basic logger activated during ActorSystem startup.
  # This logger prints the log messages to stdout (System.out).
  # Options: OFF, ERROR, WARNING, INFO, DEBUG
  stdout-loglevel = "DEBUG"

  log-dead-letters = 0

  actor {
    #provider = "akka.remote.RemoteActorRefProvider"
    provider = "akka.cluster.ClusterActorRefProvider"
    enabled-transports = ["akka.remote.netty.tcp"]
  }

  # Filter of log events that is used by the LoggingAdapter before
  # publishing log events to the eventStream.
  ##logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"

  remote {
    log-remote-lifecycle-events = off
    netty.tcp {
      hostname = "127.0.0.1"
      port = 0
    }
  }

  cluster {

    min-nr-of-members = 1

    #role {
    #  _AA_ = 1
    #}

    seed-nodes = [
      "akka.tcp://avalanchain@127.0.0.1:2551",
      "akka.tcp://avalanchain@127.0.0.1:2552"]
    #roles = [ backend ]
    auto-down-unreachable-after = 3s

    # disable legacy metrics in akka-cluster, since it is still enabled in akka-cluster by default
    metrics.enabled=off
  }

  persistence {
    journal.plugin = "inmemory-journal"
    snapshot-store.plugin = "inmemory-snapshot-store"

    ##journal.plugin = "akka.persistence.journal.leveldb"
    ##snapshot-store.plugin = "akka.persistence.snapshot-store.local"

    ##journal.leveldb.dir = "target/state/journal"
    ##snapshot-store.local.dir = "target/state/snapshots"

    # DO NOT USE THIS IN PRODUCTION !!!
    # See also https://github.com/typesafehub/activator/issues/287
    ##journal.leveldb.native = false
  }

  extensions = [ "akka.cluster.metrics.ClusterMetricsExtension" ]
}

eventuate {
  cli-dispatcher {
    executor = "thread-pool-executor"
    type = PinnedDispatcher
  }

  log {
    # Timeout for read operations from a local event log. These are batch
    # event reads during event replay made by event-sourced views, actors,
    # writers and processors and target log reads made by processors.
    read-timeout = 10s

    # Timeout for write operations to a local event log. These are batch
    # event writes made by event-sourced processors and replicators. This
    # timeout does not apply to event-sourced actor writes.
    write-timeout = 10s

    # Target batch size for writing events. It is used by the batching layer
    # to limit the size of event batches to be written atomically to an event
    # log. It also limits the size of event batches replicated from remote
    # source logs and to a local target log. Please note that this is not
    # a strict batch size limit. Event-sourced actors can still emit batches
    # of larger size (although it is very uncommon to emit that many events
    # per command).
    write-batch-size = 64

    # Maximum number of events to be replayed to an event-sourced view, actor,
    # writer or processor before replay is suspended. A suspended replay is
    # resumed automatically after the replayed event batch has been handled
    # (= replay backpressure).
    replay-batch-size = 4096

    # Maximum number of replay attempts before finally stopping the actor itself
    replay-retry-max = 10

    # Delay between consecutive replay attempts
    replay-retry-delay = 10s
  }

  log.leveldb {
    # Root directory for storing the log directories of individual event logs.
    dir = target/localdb

    # Use fsync on write.
    fsync = on

    # Minimum number of new events that must have been written before another
    # snapshot of the log's internal state (sequence number and merged vector
    # time) is written.
    state-snapshot-limit = 128

    # Maximum number of events that are physically deleted in a single batch
    # operation.
    deletion-batch-size = 100

    # Delay between two tries to physically delete all requested events while
    # keeping those that are not yet replicated.
    deletion-retry-delay = 1m
  }

  log.circuit-breaker {
    # Number of write retries after which the circuit breaker should be opened.
    open-after-retries = 2
  }

  log.replication {
    # Event replication retry delay. Event replication is delayed for the
    # given duration if a previous transfer batch was empty or failed.
    retry-delay = 5s

    # Timeout for reading events from the remote source log.
    remote-read-timeout = 10s

    # Maximum number of events to scan in a remote event log per replication
    # read request.
    remote-scan-limit = 65536

    # Minimum duration of failed communication with a remote replication
    # endpoint required to consider that endpoint as unavailable.
    failure-detection-limit = 60s

    # If turned on, notifications about updates in a source event log are sent
    # to remote replication endpoints which reduces event replication latency.
    # The impact of sending update notifications on average replication latency
    # decreases with increasing event write load. Applications with high event
    # write load may even experience increased event replication throughput if
    # update notifications are turned off.
    update-notifications = on
  }

  log.recovery {
    # Maximum number of retries of remote operations. These are operations
    # that read from remote replication endpoints.
    remote-operation-retry-max = 3

    # Delay before re-trying a remote operation after a previous failure.
    remote-operation-retry-delay = 10s

    # Timeout of remote operations.
    remote-operation-timeout = 10s

    # Timeout for deleting invalidated snapshots.
    snapshot-deletion-timeout = 30s
  }

  log.dispatchers {
    write-dispatcher {
      executor = "thread-pool-executor"
      type = PinnedDispatcher
    }

    read-dispatcher {
      type = Dispatcher
      executor = "fork-join-executor"
      fork-join-executor {
        parallelism-min = 2
        parallelism-max = 16
      }
    }
  }

  snapshot {
    # Timeout for loading a snapshot.
    load-timeout = 10m

    # Timeout for saving a snapshot.
    save-timeout = 10m
  }

  snapshot.filesystem {
    # Root directory for storing the snapshot files of individual emitters.
    dir = target/snapshots

    # Maximum number of stored snapshots per emitter. If this number is
    # exceeded during a snapshot write, older snapshots are automatically
    # deleted.
    snapshots-per-emitter-max = 3

    write-dispatcher {
      type = Dispatcher
      executor = "fork-join-executor"
      fork-join-executor {
        parallelism-min = 2
        parallelism-max = 8
      }
    }

    read-dispatcher {
      type = Dispatcher
      executor = "fork-join-executor"
      fork-join-executor {
        parallelism-min = 2
        parallelism-max = 32
      }
    }
  }
}

inmemory-read-journal {
  # Absolute path to the write journal plugin configuration section to get the event adapters from
  write-plugin = "inmemory-journal"

  # there are two modes; sequence or uuid. If set to "sequence" and NoOffset will be requested, then
  # the query will return Sequence offset types. If set to "uuid" and NoOffset will be requested, then
  # the query will return TimeBasedUUID offset types. When the query is called with Sequence then
  # the query will return Sequence offset types and if the query is called with TimeBasedUUID types then
  # the query will return TimeBasedUUID offset types.
  offset-mode = "sequence"

  # ask timeout on Futures
  ask-timeout = "10s"

  # New events are retrieved (polled) with this interval.
  refresh-interval = "100ms"

  # How many events to fetch in one query (replay) and keep buffered until they
  # are delivered downstreams.
  max-buffer-size = "100"
}

akka.actor.warn-about-java-serializer-usage = false